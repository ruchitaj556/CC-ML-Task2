{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Level 1"
      ],
      "metadata": {
        "id": "ckycUU46sBhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5hC5A6NrrH6",
        "outputId": "6e44fc42-4e77-4c98-9a3e-56557c2534b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.7)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.59)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.1)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "pip install -U langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langgraph langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZYNimEhsKb3",
        "outputId": "71a87a08-8248-47ff-9b4b-fe60b9a35070"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.7)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.42)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.59)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.1)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "MS2MORecsWEO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"langchain[google-genai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzSKEC7Hsa1f",
        "outputId": "30355ce1-f4b2-4b89-dbc3-d451d0b78d07"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain[google-genai] in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (6.0.2)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.1.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain[google-genai]) (3.2.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai->langchain[google-genai]) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai->langchain[google-genai]) (0.6.18)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.29.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (3.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (4.9.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDMW9jS0iidjyJ6sy0ZmzM2h-foYxe4atk\"\n",
        "\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "2bwB2OBjsr8_"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRtvcJHsszR-",
        "outputId": "db1f6df5-16d0-471c-ea2c-b3aede64042c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d91292bd50>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DnK_kPCs3Oe",
        "outputId": "a0d16b54-f0f7-472c-9261-4071c02ab48b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d91292bd50>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "tfIBiVERs4xQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "7mmFNLGrs_7I",
        "outputId": "490be1c0-af6c-4891-82ed-2ee950e9976d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFNk2avZtZr4",
        "outputId": "61852033-c77c-447d-c9a8-f6010379b894"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: 2/3+4*8-9\n",
            "Assistant: Following the order of operations (PEMDAS/BODMAS):\n",
            "\n",
            "1.  **Multiplication:** 4 * 8 = 32\n",
            "2.  **Addition:** 2/3 + 32 = 2/3 + 96/3 = 98/3\n",
            "3.  **Subtraction:** 98/3 - 9 = 98/3 - 27/3 = 71/3\n",
            "\n",
            "Therefore, 2/3 + 4 * 8 - 9 =  **71/3** or **23 2/3** or approximately **23.67**\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bot is already able to evaluate math expressions by satisfying BODMAS rule before any calculator tool is integrated."
      ],
      "metadata": {
        "id": "uFjuiTbQtpv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the calculator tool."
      ],
      "metadata": {
        "id": "TrImuRDp_cSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def calculator(exp: str) -> str:\n",
        "    \"\"\"Evaluates a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return str(eval(exp))\n",
        "    except:\n",
        "        return \"Invalid math expression\""
      ],
      "metadata": {
        "id": "egJm0dgq5c00"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the graph"
      ],
      "metadata": {
        "id": "HrK8CVVS_nAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"langchain[google-genai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nj1WX6F9zJF",
        "outputId": "71497f81-1d44-48b6-e055-c7a4cbaf5c98"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain[google-genai] in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (6.0.2)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.1.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain[google-genai]) (3.2.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai->langchain[google-genai]) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai->langchain[google-genai]) (0.6.18)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.29.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (3.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (4.9.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDMW9jS0iidjyJ6sy0ZmzM2h-foYxe4atk\"\n",
        "\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "nuZCYz6C9332"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tools = [calculator]\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NotmMbEH97gl",
        "outputId": "43ee78b4-d759-4ee1-a294-cb89d7ddf496"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d912136f90>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creatin a function to run the tools."
      ],
      "metadata": {
        "id": "ENGQ_-Qi_tVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "tool_node = BasicToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zyY5EET-Lcf",
        "outputId": "0e875a7f-f8e8-4843-ec83-f9f11c5cc10d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d912136f90>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the conditional_edges"
      ],
      "metadata": {
        "id": "uvNx98tY_z9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "\n",
        "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "    # It defaults to the identity function, but if you\n",
        "    # want to use a node named something else apart from \"tools\",\n",
        "    # You can update the value of the dictionary to something else\n",
        "    # e.g., \"tools\": \"my_tools\"\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "UgYh0Mqm-lG1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the graph."
      ],
      "metadata": {
        "id": "doy0V-CK_74C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "TidSfq8g-rXJ",
        "outputId": "809ef745-557c-49f8-9e8e-ceff05661840"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asking the bot questions."
      ],
      "metadata": {
        "id": "LiuChn7K__LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa12Kwzz-wmI",
        "outputId": "6b7a744a-a35b-4165-ec06-3d2cb693ca05"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: 2/3+4*8-9\n",
            "Assistant: \n",
            "Assistant: \"23.666666666666664\"\n",
            "Assistant: 23.666666666666664\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 2"
      ],
      "metadata": {
        "id": "lccHzuphAFa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing weather extractor tool."
      ],
      "metadata": {
        "id": "eopmqKRbJXfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_weather(input_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Get real-time weather using OpenWeatherMap API for a specified city.\n",
        "    \"\"\"\n",
        "    import re\n",
        "    API_KEY = \"48fd0d0f65a0556323f3c26f124760ec\"\n",
        "    # Try to extract the city name\n",
        "    match = re.search(r\"in ([a-zA-Z\\s]+)\", input_text)\n",
        "    city = match.group(1).strip() if match else input_text\n",
        "\n",
        "    try:\n",
        "        url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}&units=metric\"\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if data.get(\"cod\") != 200:\n",
        "            return f\"Error from API: {data.get('message', 'Unknown error')}\"\n",
        "\n",
        "        desc = data[\"weather\"][0][\"description\"]\n",
        "        temp = data[\"main\"][\"temp\"]\n",
        "        return f\"Weather in {city}: {desc}, {temp}C\"\n",
        "    except:\n",
        "        return f\"I am having trouble getting the weather in {city}. Please check the city name or try again later.\""
      ],
      "metadata": {
        "id": "f4qy9DKrCM9S"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_weather.run(\"What's the weather in Delhi?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYwxm1gCFo6a",
        "outputId": "8005aa01-de69-45fc-cb55-67fedea6e607"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather in Delhi: haze, 28.05C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDMW9jS0iidjyJ6sy0ZmzM2h-foYxe4atk\"\n",
        "\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "B2kAt5VlEEJN"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tools = [calculator, get_weather]\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rin-KzGBEIOc",
        "outputId": "8128b031-9887-4b5a-9bed-5fe9a9449ecf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d91219aed0>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "tool_node = BasicToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1zfO8ECETh9",
        "outputId": "647edc5a-b477-4a20-b0bf-e3c3c521266a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d91219aed0>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "\n",
        "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "    # It defaults to the identity function, but if you\n",
        "    # want to use a node named something else apart from \"tools\",\n",
        "    # You can update the value of the dictionary to something else\n",
        "    # e.g., \"tools\": \"my_tools\"\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "GlydNxcMEZVF"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XZBaraWEeWI",
        "outputId": "a7f9d5e0-e074-458d-e8d0-a53f25df3157"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: whats the weather in delhi\n",
            "Assistant: \n",
            "Assistant: \"Weather in delhi: haze, 28.05\\u00b0C\"\n",
            "Assistant: The weather in Delhi is haze with a temperature of 28.05C.\n",
            "User: whats the weather in pune\n",
            "Assistant: \n",
            "Assistant: \"Weather in pune: overcast clouds, 22.83\\u00b0C\"\n",
            "Assistant: The weather in Pune is overcast clouds with a temperature of 22.83C.\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrated internet search tool instead fashion recommendor tool . chatbot can browse through the internet to find the current trends."
      ],
      "metadata": {
        "id": "8u8gvwNhNRbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-tavily"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZrr2cHFKsxj",
        "outputId": "e0852ddd-cf65-4eb4-dc16-a845441ddcc5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-tavily in /usr/local/lib/python3.11/dist-packages (0.1.6)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (3.11.15)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (0.3.25)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (0.3.59)\n",
            "Requirement already satisfied: mypy<2.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (4.13.2)\n",
            "Requirement already satisfied: mypy_extensions>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from mypy<2.0.0,>=1.15.0->langchain-tavily) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2025.4.26)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "\n"
      ],
      "metadata": {
        "id": "hjoO0QJzKwjB"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool]\n",
        "tool.invoke(\"What's a 'node' in LangGraph?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOgAnU43LTDd",
        "outputId": "caceb4b5-5e95-47ac-ef49-2293cf282f21"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"What's a 'node' in LangGraph?\",\n",
              " 'follow_up_questions': None,\n",
              " 'answer': None,\n",
              " 'images': [],\n",
              " 'results': [{'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
              "   'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
              "   'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
              "   'score': 0.5008063,\n",
              "   'raw_content': None},\n",
              "  {'title': 'LangGraph Tutorial for Beginners - Analytics Vidhya',\n",
              "   'url': 'https://www.analyticsvidhya.com/blog/2025/05/langgraph-tutorial-for-beginners/',\n",
              "   'content': 'Now that we have built the simplest graph in the above section, in this section,I will show you how to use LangGraph to build a support chatbot, starting with basic functionality and progressively adding features like web search, memory, and human-in-loop. Also Read: Build an AI Coding Agent with LangGraph by LangChain Generative AI| DeepSeek| OpenAI Agent SDK| LLM Applications using Prompt Engineering| DeepSeek from Scratch| Stability.AI| SSM & MAMBA| RAG Systems using LlamaIndex| Building LLMs for Code| Python| Microsoft Excel| Machine Learning| Deep Learning| Mastering Multimodal RAG| Introduction to Transformer Model| Bagging & Boosting| Loan Prediction| Time Series Forecasting| Tableau| Business Analytics| Vibe Coding in Windsurf| Model Deployment using FastAPI| Building Data Analyst AI Agent| Getting started with OpenAI o3-mini| Introduction to Transformers and Attention Mechanisms',\n",
              "   'score': 0.12658015,\n",
              "   'raw_content': None}],\n",
              " 'response_time': 1.55}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tools = [calculator, get_weather, tool]\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKoVLxbQMY-c",
        "outputId": "b36230d7-daf8-452a-bef0-331825e5d879"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d91217e690>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drUrx5ecMx97",
        "outputId": "abe1445d-b12d-4265-801c-ff126d9465b1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d91217e690>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "\n",
        "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "    # It defaults to the identity function, but if you\n",
        "    # want to use a node named something else apart from \"tools\",\n",
        "    # You can update the value of the dictionary to something else\n",
        "    # e.g., \"tools\": \"my_tools\"\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "2IkClHPlM1lc"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpXLSimnLf-2",
        "outputId": "f58ab98e-52c1-4ac8-be7a-a6fa67fb489e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: whats trending in tokyo\n",
            "Assistant: \n",
            "Assistant: {\"query\": \"trending in Tokyo\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"NEW & TRENDING IN TOKYO | TIMELESS TOKYO - Official luxury travel ...\", \"url\": \"https://timelesstokyo.com/trend\", \"content\": \"COMFORTABLE NEW LUXURY ACCOMMODATIONS Tokyo hospitality has always been in a class of its own - a class now redefined by boutique hotels and next-generation luxury experiences that rewrite the status quo and delight the discerning traveler. TOKYO'S NEW ART SPACES Ride the cutting edge of culture in an ever-changing city. TOKYO'S NEW ART SPACES Ride the cutting edge of culture in an ever-changing city. COMFORTABLE NEW LUXURY ACCOMMODATIONS Tokyo hospitality has always been in a class of its own - a class now redefined by boutique hotels and next-generation luxury experiences that rewrite the status quo and delight the discerning traveler.\", \"score\": 0.5510187, \"raw_content\": null}, {\"title\": \"New & Trending | The Official Tokyo Travel Guide, GO TOKYO\", \"url\": \"https://www.gotokyo.org/en/new-and-now/new-and-trending/index.html\", \"content\": \"Skip to main content. GO TOKYO The Official Tokyo Travel Guide Main content starts here. Craftsmanship in Tokyo: Japanese Craft Workshops Led by Skilled Artisans First Look Into Ginza Sony Park: A New Hub for Art and Music Tokyo Esports Guide Michelin Guide Tokyo: Showcasing some of Japan's Top Flavors Three Tokyo Cafes Taking Sustainability to the Next Level Ueno Station\\u00e2\\u0080\\u0099s new look Tokyo\\u00e2\\u0080\\u0099s Wonderful World of Stationery Japanese Cuisine and Sake in Kabutocho, a Nihonbashi Neighborhood Experiencing a Renaissance VR Vacations and Esport Adventures in Ginza, Asakusa and at Tokyo Tower Top-Notch Mt. Fuji Viewpoints in Tokyo: TOKYO SKYTREE, the Tokyo Metropolitan Government Building and Haneda Airport New Tokyo Landmarks near Shibuya and Shinjuku Stations GO TOKYO Return to top of page\", \"score\": 0.5142789, \"raw_content\": null}], \"response_time\": 1.52}\n",
            "Assistant: According to timelesstokyo.com, comfortable new luxury accommodations are trending in Tokyo. Boutique hotels and next-generation luxury experiences are redefining the status quo. Additionally, new art spaces are trending.\n",
            "\n",
            "According to gotokyo.org, some of what's new and trending includes: craftsmanship workshops, Ginza Sony Park, esports, Michelin Guide Tokyo, sustainable cafes, Ueno Station's new look, stationery, cuisine and sake in Kabutocho, VR vacations, Mt. Fuji viewpoints, and new landmarks near Shibuya and Shinjuku Stations.\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 3"
      ],
      "metadata": {
        "id": "i39ZwCgOKTYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Routing logic and which tool to be used based on prompt already implemented after defining the tools in Level 2. doing once more."
      ],
      "metadata": {
        "id": "TN_WiAxlQYRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tools = [calculator, get_weather, tool]\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIJK_5LKRMr7",
        "outputId": "8a32d5c8-5651-4786-e404-4063f95f81c8"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d9110cad90>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm03z4zgRALI",
        "outputId": "9e7fc297-0d49-4665-b94a-4c372b5ae247"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78d9110cad90>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "\n",
        "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
        "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "    # It defaults to the identity function, but if you\n",
        "    # want to use a node named something else apart from \"tools\",\n",
        "    # You can update the value of the dictionary to something else\n",
        "    # e.g., \"tools\": \"my_tools\"\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "O1X1GJVkRSIw"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tried doing the memory thing, but not working. Could'nt fix because of time constraints."
      ],
      "metadata": {
        "id": "ZnusGqaoRVts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool, calculator, get_weather])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "DyvTKzxjKZQm"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}"
      ],
      "metadata": {
        "id": "-Zt0E0mfPWTp"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "  events = graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
        "    config,\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "  for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "q9qL0nygPDO8",
        "outputId": "95589214-46bf-455c-a4b5-b8234df488e1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: hi, i am ruchita\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi, i am ruchita\n",
            "User: What do you know about LangGraph?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What do you know about LangGraph?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-575302354281>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mstream_graph_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-575302354281>\u001b[0m in \u001b[0;36mstream_graph_updates\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2342\u001b[0m                 \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2343\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2344\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36m_defaults\u001b[0;34m(self, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   2233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2235\u001b[0m                 \u001b[0;34mf\"Checkpointer requires one or more of the following 'configurable' keys: {[s.id for s in checkpointer.config_specs]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-575302354281>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What do you know about LangGraph?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mstream_graph_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-575302354281>\u001b[0m in \u001b[0;36mstream_graph_updates\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Assistant:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2341\u001b[0m                 \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m                 \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2343\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2344\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m                 \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36m_defaults\u001b[0;34m(self, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2235\u001b[0m                 \u001b[0;34mf\"Checkpointer requires one or more of the following 'configurable' keys: {[s.id for s in checkpointer.config_specs]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']"
          ]
        }
      ]
    }
  ]
}